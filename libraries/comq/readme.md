# ComQ

Distributed system communications over [AMQP](https://github.com/amqp-node/amqplib) for
Node.js.

## Features

1. Dynamic topology
2. [Request](#request)-[reply](#reply) (RPC)
3. Events ([pub](#emission)/[sub](#consumption))
4. [Consumer acknowledgements](#acknowledgements)
5. [Publisher confirms](#io-channels)
6. [Flow control](#io-channels)
7. [Content encoding](#encoding)
8. [Graceful shutdown](#graceful-shutdown)
9. Broker restart or connection loss [resilience](#persistence)

> Features are described in the [`features`](features) directory. To run them you should start
> RabbitMQ server with `docker compose up -d`, then execute `npm run test:features`

## Installation

`npm i comq`

## Connect

`async connect(url: string): IO`

`url` is passed
to [`amqplib.connect`](https://amqp-node.github.io/amqplib/channel_api.html#connect).

### Example

```javascript
const { connect } = require('comq')

const url = 'amqp://developer:secret@localhost'
const io = await connect(url)

// ...

await io.close()
```

## Definitions

The following documentation refers to a few terms:

**Request** is an AMQP message that has the `replyTo` and `correlationId` properties set.

**Reply** is an AMQP message sent in response to a Request and sent to the queue specified in
the `replyTo` property of the Request. The `correlationId` property of the Reply is set to the same
value as in the Request.

**Event** is an AMQP message that is published to an exchange.

**Producer** is an application role that receives Requests and produces Replies and Events.

**Consumer** is an application role that sends Requests and receives Replies and Events.

## Reply

`async IO.reply(queue: string, producer)`

`producer` function's signature is `async? (message: any): any`

Assert a `queue` and start consuming messages (Requests). Received messages are decoded and
the resulting content is passed to the specified `producer`. The result generated by the `producer`
is then encoded and sent back to the queue specified in the `replyTo` property, along with
a `correlationId` that has the same value as in the original Request.

Reply message is encoded using the same encoding format as the Request message, if it is specified
and supported, unless `producer` returned `Buffer`, in which case encoding format will be set
to `application/octet-stream`. If encoding format of the Request message isn't specified or
supported and `producer` has returned value that isn't a `Buffer`, then exception is thrown.

> If incoming message doesn't have a `replyTo` property, an exception is thrown without
> calling `producer`.

> `replyTo` queue is not asserted, therefore a Request message with `replyTo` referring to a
> non-existent queue will cause an AMQP channel error.

### Example

```javascript
await io.reply('add_numbers', ({ a, b }) => (a + b))
```

## Request

`async IO.request(queue: string, payload: any, [encoding: string])`

Send encoded Request message with `replyTo` and `correlationId` properties set and
return decoded Reply content.

On the initial call, a queue for Requests and a [transient](#persistence) queue for Replies are
asserted.

### Example

```javascript
const sum = await io.request('add_numbers', { a: 1, b: 2 })

console.log(sum) // 3
```

## Consumption

`async IO.consume(exchange: string, group: string, consumer)`

`consumer` function's signature is `async? (message: any): void`

Assert fanout `exchange` and durable queue for the Consumer `group`, and then bind the queue to the
exchange. Essentially, one Event message is delivered to a single Consumer within *each group*.

> Typically, the value of `group` refers to the name of a microservice running in multiple
> instances.

### Example

```javascript
await io.consume('numbers_added', 'logger', (payload) => {
  console.log(`${payload.a} was added to ${payload.b}`)
})
```

## Emission

`async IO.emit(exchange: string, payload: any, [encoding: string])`

Publish encoded Event message to the `exchange`.

On the initial call,
a [fanout exchange](https://www.rabbitmq.com/tutorials/amqp-concepts.html#exchanges) is
asserted.

### Example

```javascript
await io.emit('numbers_added', { a: 1, b: 2 })
```

## Encoding

By default, outgoing message contents are encoded with [msgpack](https://msgpack.org) and
the `contentType` property is set to `application/msgpack`. If encoding format is
specified ([request](#request), [emit](#emission)) and supported, contents are encoded accordingly.

Exceptions are Buffers, which are sent without encoding and the `contentType` property set
to specified encoding format or `application/octet-stream` if it's not specified.

Incoming messages are decoded based on the presence and value of the `contentType` property. If the
header is present and its value is supported, the message is decoded. If the header is missing or
its value is `application/octet-stream` or is not supported, the message is passed as a raw Buffer
object.

The following content types are supported:

- `application/msgpack`
- `application/json`

## IO Channels

`IO` lazy creates two channels: input and output.

Input channel is used to consume Requests and Events. It
has [prefetch count](https://www.rabbitmq.com/confirms.html#channel-qos-prefetch) [initially](#cause-effect-confirmation-lag)
set to `300` (currently, non-configurable).

Output channel is
a [ConfirmChannel](https://amqp-node.github.io/amqplib/channel_api.html#confirmchannel) used to send
Requests, emit Events, send *and consume* Replies.

## Graceful Shutdown

`async IO.seal()` closes input channel, that is, guarantees no more Requests or Events will be
consumed. Output channel remains available.

`async IO.close()` closes both input (if it hasn't been closed before) and output channels.

It is recommended to call `.seal()`, finish processing current Requests and Events, and then
call `.close()`.

## Persistence

Queues and exchanges are `durable`. [Transient](#request) queues have 1
hour [TTL](https://www.rabbitmq.com/ttl.html#queue-ttl) (non-configurable currently). Outgoing
messages are [`persistent`](https://amqp-node.github.io/amqplib/channel_api.html#channel_publish).

## Acknowledgements

Incoming messages are "positive
acknowledged" ([ack](https://amqp-node.github.io/amqplib/channel_api.html#channel_ack)), unless
message handler function throws an exception. Messages are **not** "negative
acknowledged" ([nack](https://amqp-node.github.io/amqplib/channel_api.html#channel_nack)) as it's
assumed, that the handler's exception will cause
the [process to crash](https://www.reactivedesignpatterns.com/patterns/let-it-crash.html). In this
scenario, RabbitMQ [will requeue](https://www.rabbitmq.com/confirms.html#automatic-requeueing) the
message due to a connection loss.

See [Consumer Acknowledgements and Publisher Confirms](https://www.rabbitmq.com/confirms.html).

## Notes

### "At least once"

RabbitMQ delivers a message **before** it has been written to disk, therefore provides "at least
once" delivery guarantee. Considering that, system using communications over AMQP
must be idempotent.

### Cause-Effect Confirmation Lag

Let's consider a scenario where an application receives messages ("causes") from a queue, processes
them, and then publishes expected messages ("effects") to another queue. An example of this is a
Producer that consumes Requests and produces Replies. The rate at which messages are consumed is
limited by a "prefetch count", which is the maximum number of concurrent Requests that can be
processed at the same time.

For simplicity, let's assume that the prefetch count is set to 1. After a "cause" message is
consumed, the next message in the queue is held until the current message is acknowledged ("ack").
The current message is acknowledged once the Producer function is completed, which means that an "
effect" message has been successfully published using the ConfirmChannel. This "effect" message is
considered to be published when a confirmation is received from the broker.

In summary, the next "cause" message will be consumed from the queue only after the "effect" message
publication has been confirmed. Due to the ["at least once" effect](#-at-least-once-), *there is a
delay between the moment when a Reply **is delivered** to the Consumer and the moment when the
next Request is consumed from the Request queue*.

<a href="https://miro.com/app/board/uXjVOoy0ImU=/?moveToWidget=3458764545934661005&cot=14">
<picture>
<source media="(prefers-color-scheme: dark)" srcset="docs/lag-dark.jpg">
<img alt="Confirmation Lag" width="640" src="docs/lag-light.jpg">
</picture>
</a>

A lightweight Producer (one that produces responses quickly) can result in being "overloaded"
from the Consumer's perspective (that is, does not consume messages with an expected rate), even
though the Producer being idle while waiting for response publication confirmations.

#### Prefetch Confirmation Gap

The problem of "overloaded" idling Producer may be addressed by increasing the prefetch count of the
input channel in the incoming message handlers ([IO.consume](#consumption) and [IO.reply](#reply))
for each response sent, before receiving confirmation from the broker.

> The solution is not implemented yet.
